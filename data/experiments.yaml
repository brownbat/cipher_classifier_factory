- data_params:
    ciphers:
    - english
    - caesar
    - vigenere
    - columnar_transposition
    num_samples: 10000
    sample_length: 500
  experiment_id: exp_1_1-layer
  hyperparams:
    batch_size: 32
    dropout_rate: 0.015
    embedding_dim: 128
    epochs: 10
    hidden_dim: 128
    learning_rate: 0.001
    num_layers: 1
  metrics:
    conf_matrix:
    - - - 0
        - 0
        - 1
        - 509
      - - 0
        - 397
        - 90
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 0
        - 0
        - 1
        - 510
    - - - 251
        - 0
        - 0
        - 259
      - - 0
        - 304
        - 183
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 167
        - 0
        - 0
        - 344
    - - - 439
        - 0
        - 0
        - 71
      - - 0
        - 401
        - 86
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 359
        - 0
        - 0
        - 152
    - - - 444
        - 0
        - 0
        - 66
      - - 0
        - 465
        - 22
        - 0
      - - 0
        - 89
        - 403
        - 0
      - - 249
        - 0
        - 1
        - 261
    - - - 338
        - 0
        - 0
        - 172
      - - 0
        - 487
        - 0
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 176
        - 0
        - 0
        - 335
    - - - 476
        - 0
        - 0
        - 34
      - - 0
        - 487
        - 0
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 41
        - 0
        - 0
        - 470
    - - - 507
        - 0
        - 0
        - 3
      - - 0
        - 485
        - 2
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 35
        - 0
        - 0
        - 476
    - - - 505
        - 0
        - 0
        - 5
      - - 0
        - 487
        - 0
        - 0
      - - 0
        - 1
        - 491
        - 0
      - - 18
        - 0
        - 0
        - 493
    - - - 498
        - 0
        - 0
        - 12
      - - 0
        - 487
        - 0
        - 0
      - - 0
        - 1
        - 491
        - 0
      - - 4
        - 0
        - 0
        - 507
    - - - 504
        - 0
        - 0
        - 6
      - - 0
        - 487
        - 0
        - 0
      - - 0
        - 0
        - 492
        - 0
      - - 6
        - 0
        - 0
        - 505
    train_loss:
    - 0.7223450700044632
    - 0.48617668187618257
    - 0.4592051218748093
    - 0.4462181420326233
    - 0.40289248019456864
    - 0.23191980870068074
    - 0.08222060598433018
    - 0.03800401440821588
    - 0.025723843277432025
    - 0.020866762490943075
    val_accuracy:
    - 0.6995
    - 0.6955
    - 0.742
    - 0.7865
    - 0.826
    - 0.9625
    - 0.98
    - 0.988
    - 0.9915
    - 0.994
    val_loss:
    - 0.4921956133274805
    - 0.5527575815480853
    - 0.4756994758333479
    - 0.46000389920340645
    - 0.3353786442487959
    - 0.12383418270046749
    - 0.05726718655713494
    - 0.03596836845538327
    - 0.025164250909010807
    - 0.02576478983881691
- data_params:
    ciphers:
    - english
    - caesar
    - vigenere
    - columnar_transposition
    num_samples: 10000
    sample_length: 500
  experiment_id: exp_2_2-layers
  hyperparams:
    batch_size: 32
    dropout_rate: 0.015
    embedding_dim: 128
    epochs: 5
    hidden_dim: 128
    learning_rate: 0.001
    num_layers: 2
  metrics:
    conf_matrix:
    - - - 0
        - 0
        - 1
        - 514
      - - 0
        - 372
        - 98
        - 0
      - - 0
        - 0
        - 508
        - 0
      - - 0
        - 0
        - 0
        - 507
    - - - 496
        - 0
        - 1
        - 18
      - - 0
        - 372
        - 98
        - 0
      - - 0
        - 0
        - 508
        - 0
      - - 474
        - 0
        - 0
        - 33
    - - - 322
        - 0
        - 0
        - 193
      - - 0
        - 374
        - 96
        - 0
      - - 0
        - 13
        - 495
        - 0
      - - 127
        - 0
        - 0
        - 380
    - - - 422
        - 0
        - 0
        - 93
      - - 0
        - 372
        - 98
        - 0
      - - 0
        - 0
        - 508
        - 0
      - - 28
        - 0
        - 0
        - 479
    - - - 425
        - 0
        - 0
        - 90
      - - 0
        - 372
        - 98
        - 0
      - - 0
        - 0
        - 508
        - 0
      - - 15
        - 0
        - 0
        - 492
    train_loss:
    - 0.6870881464481354
    - 0.49505718648433683
    - 0.47833845710754397
    - 0.39675017815828323
    - 0.30071399196982385
    val_accuracy:
    - 0.6935
    - 0.7045
    - 0.7855
    - 0.8905
    - 0.8985
    val_loss:
    - 0.49683894335277495
    - 0.49418792507005116
    - 0.46075653604098726
    - 0.3129961419673193
    - 0.28780381405164324
