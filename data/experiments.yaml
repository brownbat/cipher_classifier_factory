- data_params:
    ciphers:
    - english
    - caesar
    - vigenere
    - columnar_transposition
    num_samples: 8000
    sample_length: 400
  experiment_id: exp_1
  hyperparams:
    batch_size: 32
    dropout_rate: 0.015
    embedding_dim: 64
    epochs: 15
    hidden_dim: 192
    learning_rate: 0.004
    num_layers: 20
  metrics:
    conf_matrix:
    - - - 280
        - 0
        - 0
        - 122
      - - 0
        - 232
        - 147
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 195
        - 0
        - 0
        - 199
    - - - 0
        - 0
        - 0
        - 402
      - - 0
        - 39
        - 340
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 2
        - 0
        - 1
        - 391
    - - - 0
        - 0
        - 0
        - 402
      - - 0
        - 377
        - 2
        - 0
      - - 0
        - 2
        - 423
        - 0
      - - 0
        - 0
        - 0
        - 394
    - - - 401
        - 0
        - 0
        - 1
      - - 0
        - 379
        - 0
        - 0
      - - 0
        - 4
        - 421
        - 0
      - - 392
        - 0
        - 0
        - 2
    - - - 126
        - 0
        - 0
        - 276
      - - 0
        - 361
        - 18
        - 0
      - - 0
        - 1
        - 424
        - 0
      - - 1
        - 0
        - 1
        - 392
    - - - 283
        - 0
        - 0
        - 119
      - - 0
        - 374
        - 5
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 15
        - 0
        - 0
        - 379
    - - - 250
        - 0
        - 0
        - 152
      - - 0
        - 379
        - 0
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 5
        - 0
        - 0
        - 389
    - - - 342
        - 0
        - 0
        - 60
      - - 0
        - 374
        - 5
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 51
        - 0
        - 0
        - 343
    - - - 281
        - 0
        - 0
        - 121
      - - 0
        - 377
        - 2
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 8
        - 0
        - 0
        - 386
    - - - 337
        - 0
        - 0
        - 65
      - - 0
        - 377
        - 2
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 12
        - 0
        - 0
        - 382
    - - - 335
        - 0
        - 0
        - 67
      - - 0
        - 378
        - 1
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 11
        - 0
        - 0
        - 383
    - - - 362
        - 0
        - 0
        - 40
      - - 0
        - 378
        - 1
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 10
        - 0
        - 0
        - 384
    - - - 365
        - 0
        - 0
        - 37
      - - 0
        - 379
        - 0
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 13
        - 0
        - 0
        - 381
    - - - 348
        - 0
        - 0
        - 54
      - - 0
        - 378
        - 1
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 7
        - 0
        - 0
        - 387
    - - - 364
        - 0
        - 0
        - 38
      - - 0
        - 378
        - 1
        - 0
      - - 0
        - 0
        - 425
        - 0
      - - 6
        - 0
        - 0
        - 388
    train_loss:
    - 0.8420112420618534
    - 0.6403909401595592
    - 0.6440151953697204
    - 0.38881477192044256
    - 0.3719550915807486
    - 0.26579382188618184
    - 0.23550409412011505
    - 0.19562201410531999
    - 0.17876367267221213
    - 0.1912970994412899
    - 0.14903956074267627
    - 0.1335337470844388
    - 0.11680602290667594
    - 0.09595573749393224
    - 0.09279117446392775
    training_time: 359.3972556591034
    val_accuracy:
    - 0.71
    - 0.534375
    - 0.74625
    - 0.751875
    - 0.814375
    - 0.913125
    - 0.901875
    - 0.9275
    - 0.918125
    - 0.950625
    - 0.950625
    - 0.968125
    - 0.96875
    - 0.96125
    - 0.971875
    val_loss:
    - 0.5579533421993256
    - 0.6838271176815033
    - 0.3845003706216812
    - 0.3566536104679108
    - 0.3674116912484169
    - 0.2333459235727787
    - 0.2241566914319992
    - 0.18301613509655
    - 0.20655705019831658
    - 0.1550498091429472
    - 0.137553318887949
    - 0.11315046411007643
    - 0.10857700020074844
    - 0.11006441626697779
    - 0.07324642941355705
  model_filename: data/models/model_exp_1_20231209_183315.pt
- data_params:
    ciphers:
    - english
    - caesar
    - vigenere
    - columnar_transposition
    num_samples: 8000
    sample_length: 400
  experiment_id: exp_2
  hyperparams:
    batch_size: 32
    dropout_rate: 0.015
    embedding_dim: 64
    epochs: 15
    hidden_dim: 192
    learning_rate: 0.003
    num_layers: 20
  metrics:
    conf_matrix:
    - - - 388
        - 0
        - 0
        - 1
      - - 0
        - 237
        - 150
        - 1
      - - 0
        - 0
        - 410
        - 0
      - - 410
        - 0
        - 0
        - 3
    - - - 328
        - 0
        - 0
        - 61
      - - 0
        - 255
        - 132
        - 1
      - - 0
        - 0
        - 410
        - 0
      - - 238
        - 0
        - 0
        - 175
    - - - 353
        - 0
        - 0
        - 36
      - - 0
        - 257
        - 130
        - 1
      - - 0
        - 0
        - 410
        - 0
      - - 67
        - 0
        - 0
        - 346
    - - - 351
        - 0
        - 0
        - 38
      - - 0
        - 387
        - 0
        - 1
      - - 0
        - 408
        - 2
        - 0
      - - 15
        - 0
        - 0
        - 398
    - - - 379
        - 0
        - 0
        - 10
      - - 0
        - 386
        - 1
        - 1
      - - 0
        - 1
        - 408
        - 1
      - - 17
        - 0
        - 0
        - 396
    - - - 385
        - 0
        - 0
        - 4
      - - 1
        - 386
        - 0
        - 1
      - - 0
        - 1
        - 409
        - 0
      - - 19
        - 0
        - 0
        - 394
    - - - 381
        - 0
        - 0
        - 8
      - - 1
        - 385
        - 1
        - 1
      - - 0
        - 2
        - 408
        - 0
      - - 3
        - 0
        - 0
        - 410
    - - - 385
        - 0
        - 0
        - 4
      - - 1
        - 385
        - 1
        - 1
      - - 0
        - 2
        - 408
        - 0
      - - 3
        - 0
        - 0
        - 410
    - - - 389
        - 0
        - 0
        - 0
      - - 1
        - 385
        - 1
        - 1
      - - 0
        - 3
        - 407
        - 0
      - - 5
        - 0
        - 0
        - 408
    - - - 378
        - 0
        - 0
        - 11
      - - 1
        - 386
        - 0
        - 1
      - - 0
        - 5
        - 405
        - 0
      - - 2
        - 0
        - 0
        - 411
    - - - 383
        - 0
        - 0
        - 6
      - - 0
        - 385
        - 1
        - 2
      - - 0
        - 1
        - 409
        - 0
      - - 1
        - 0
        - 0
        - 412
    - - - 389
        - 0
        - 0
        - 0
      - - 1
        - 386
        - 0
        - 1
      - - 0
        - 4
        - 406
        - 0
      - - 3
        - 0
        - 0
        - 410
    - - - 381
        - 0
        - 0
        - 8
      - - 1
        - 385
        - 1
        - 1
      - - 0
        - 1
        - 409
        - 0
      - - 4
        - 0
        - 0
        - 409
    - - - 386
        - 0
        - 0
        - 3
      - - 1
        - 386
        - 0
        - 1
      - - 0
        - 3
        - 407
        - 0
      - - 4
        - 0
        - 0
        - 409
    - - - 380
        - 0
        - 0
        - 9
      - - 0
        - 386
        - 0
        - 2
      - - 0
        - 1
        - 409
        - 0
      - - 4
        - 0
        - 0
        - 409
    train_loss:
    - 0.9585205875337124
    - 0.6189025841653347
    - 0.47333631418645383
    - 0.40048848621547223
    - 0.3225879468396306
    - 0.08847661718260497
    - 0.0508507584198378
    - 0.029145252705784514
    - 0.021983517205808312
    - 0.019970651037874633
    - 0.019760002488619647
    - 0.014123216744046659
    - 0.016461259968054948
    - 0.024239701948245054
    - 0.06734626744117123
    training_time: 388.7917821407318
    val_accuracy:
    - 0.64875
    - 0.73
    - 0.85375
    - 0.71125
    - 0.980625
    - 0.98375
    - 0.99
    - 0.9925
    - 0.993125
    - 0.9875
    - 0.993125
    - 0.994375
    - 0.99
    - 0.9925
    - 0.99
    val_loss:
    - 0.5933686566352844
    - 0.5337429398298263
    - 0.38073538422584535
    - 0.4120355832576752
    - 0.0888333086669445
    - 0.05447890921495855
    - 0.05041458426043391
    - 0.03691701332572848
    - 0.04330626211129129
    - 0.05047812485601753
    - 0.03999013405176811
    - 0.03968888391042128
    - 0.05115404567332007
    - 0.04147172896424309
    - 0.03774265088839456
  model_filename: data/models/model_exp_2_20231209_180824.pt
